#---------------------------------#
#       Hyper Parameters        
#---------------------------------#
K_NEIGHBOR: 2
SINKHORN_ITERS: 8
BT_DIST_MASK: True
DIST_THRESH: 45 

#---------------------------------#
#         Model Structure
#      1. Node_Encoder
#      2. Edge_Encoder
#      3. Static_Graph_Model
#      4. Dynamic_Graph_Model
#      5. Fuse_Model
#      6. affinity_model
#---------------------------------#

#---------------------------------#
node_encoder:
  backbone: 'fastreid_market_BOT_R50_ibn'
  weight_path: 'model_weights/fastreid/market_bot_R50-ibn.pth'
  dims_list: [2048,512,128,32,32]
  layer_type: 'linear'
  layer_bias: False
  norm_type: 'batchNorm'
  activate_func: 'lrelu'
  lrelu_slope: 0.1


#---------------------------------#
edge_encoder:
  edge_type: 'DIOUd5'
  dims_list: [5,16,16]
  layer_type: 'linear'
  layer_bias: False
  norm_type: 'batchnorm'
  activate_func: 'lrelu'
  lrelu_slope: 0.1
  # static graph construction settings
  bt_cosine: False 
  bt_self_loop: False
  bt_directed: True

#---------------------------------#
#   3. Static_Graph_Model
# There are three GCN , and the dimension of each layer
# is defined in the following list.
#---------------------------------#
static_graph_conv:
  layers_num: 3  # the number of static graph conv layers 
  node_update_model:
    aggr: 'max'
    message_model:
      dims_list:
        - [48,64,64]
        - [80,96,96]
        - [112,128,128]
      layer_type: 'linear'
      layer_bias: False
      norm_type: 'graphnorm'
      activate_func: 'lrelu'
      lrelu_slope: 0.1
    res_model:
      dims_list:
         - [32,64]
         - [64,96]
         - [96,128]
      layer_type: 'linear'
      layer_bias: False
      norm_type: 'graphnorm'
      activate_func: 'lrelu'
      lrelu_slope: 0.1
    update_model:
      dims_list:
        - [64,64]
        - [96,96]
        - [128,128]
      layer_type: 'linear'
      layer_bias: False
      norm_type: 'graphnorm'
      activate_func: 'lrelu'
      lrelu_slope: 0.1  
#----------------Deprecated-----------------#
  edge_update_model:
    edge_mode: 'NodeConcat' # optional: NodeConcat NodeDiff None
    # if NodeDiff 
    #  [80,56,32,32]  [128,64,48,48]
    dims_list:
      - []                # using initiali edge embedding
      - [144,80,16]
      - []
    layer_type: 'linear'
    layer_bias: False
    norm_type: 'batchnorm'
    activate_func: 'lrelu'
    lrelu_slope: 0.1

#---------------------------------#
#   4. Dynamic_Graph_Model
# There are three GCN , and the dimension of each layer
# is defined in the following list.
#---------------------------------#
dynamic_graph_conv:
  # dynamic graph construction settings
  bt_cosine: True
  bt_self_loop: False
  bt_directed: True
  # module layer settings 
  layers_num: 2
  aggr: 'max'
  message_model:
    dims_list:
      - [128,112,96,96]
      - [192,160,128,128]
    layer_type: 'linear'
    layer_bias: False
    norm_type: 'graphnorm'
    activate_func: 'lrelu'
    lrelu_slope: 0.1
  update_model:
    dims_list:
      - []
      - []
    layer_type: 'linear'
    layer_bias: False
    norm_type: 'graphnorm'
    activate_func: 'lrelu'
    lrelu_slope: 0.1

#---------------------------------#
#   5. Dynamic_Graph_Model
#---------------------------------#
fuse_model:
  # [in_dim , mid_dim, out_dim]
  dims_list: 
    - [512,512,1024]
    - [1536,768,384,192,192] 
  layer_type: 'Conv1d'
  layer_bias: False
  norm_type: 'graphnorm'
  activate_func: 'lrelu'
  lrelu_slope: 0.2

#---------------------------------#
#   6. affinity_model
#---------------------------------#
affinity_model:
  # [in_dim , mid_dim, out_dim]
  dims_list: [3,1]
  layer_type: 'linear'
  layer_bias: False
  norm_type: 'None'
  activate_func: 'sigmoid'
  lrelu_slope: 0
